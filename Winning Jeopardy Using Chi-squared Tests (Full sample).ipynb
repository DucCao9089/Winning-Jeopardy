{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for a few decades, and is a major force in popular culture. Let's say a friend of mine want to compete on Jeopardy, and my job is to look for any edge I can get to help him win. In this project, I will work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help my friend win. The dataset is available on [reddit](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duc Cao\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from scipy.stats import chisquare\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "jeopardy=pd.read_json('jEOPARDY_QUESTIONS1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          category    air_date  \\\n",
      "0                          HISTORY  2004-12-31   \n",
      "1  ESPN's TOP 10 ALL-TIME ATHLETES  2004-12-31   \n",
      "2      EVERYBODY TALKS ABOUT IT...  2004-12-31   \n",
      "3                 THE COMPANY LINE  2004-12-31   \n",
      "4              EPITAPHS & TRIBUTES  2004-12-31   \n",
      "\n",
      "                                            question value       answer  \\\n",
      "0  'For the last 8 years of his life, Galileo was...  $200   Copernicus   \n",
      "1  'No. 2: 1912 Olympian; football star at Carlis...  $200   Jim Thorpe   \n",
      "2  'The city of Yuma in this state has a record a...  $200      Arizona   \n",
      "3  'In 1963, live on \"The Art Linkletter Show\", t...  $200  McDonald\\'s   \n",
      "4  'Signer of the Dec. of Indep., framer of the C...  $200   John Adams   \n",
      "\n",
      "       round  show_number  \n",
      "0  Jeopardy!         4680  \n",
      "1  Jeopardy!         4680  \n",
      "2  Jeopardy!         4680  \n",
      "3  Jeopardy!         4680  \n",
      "4  Jeopardy!         4680  \n",
      "\n",
      "\n",
      "Index(['category', 'air_date', 'question', 'value', 'answer', 'round',\n",
      "       'show_number'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "(216930, 7)\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216930 entries, 0 to 216929\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   category     216930 non-null  object\n",
      " 1   air_date     216930 non-null  object\n",
      " 2   question     216930 non-null  object\n",
      " 3   value        213296 non-null  object\n",
      " 4   answer       216930 non-null  object\n",
      " 5   round        216930 non-null  object\n",
      " 6   show_number  216930 non-null  int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 11.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Explore the data\n",
    "print(jeopardy.head())\n",
    "print('\\n')\n",
    "print(jeopardy.columns)\n",
    "print('\\n')\n",
    "print(jeopardy.shape)\n",
    "print('\\n')\n",
    "print(jeopardy.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             copernicus\n",
       "1                             jim thorpe\n",
       "2                                arizona\n",
       "3                              mcdonalds\n",
       "4                             john adams\n",
       "                       ...              \n",
       "216925                          turandot\n",
       "216926                        a titmouse\n",
       "216927                      clive barker\n",
       "216928                          geronimo\n",
       "216929    grigori alexandrovich potemkin\n",
       "Name: clean_answer, Length: 216930, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the question and answer columns\n",
    "jeopardy['clean_question']=jeopardy['question'].str.replace(r'[^\\w\\s]','').str.lower()\n",
    "jeopardy['clean_answer']=jeopardy['answer'].str.replace(r'[^\\w\\s]','').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the value column\n",
    "jeopardy['clean_value']=jeopardy['value'].str.replace('\\W+','').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set air date in datetime \n",
    "jeopardy['air_date']=pd.to_datetime(jeopardy['air_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How often the answer is deducible from the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "def answer_match_question(row):\n",
    "    split_answer=row['clean_answer'].split()\n",
    "    split_question=row['clean_question'].split()\n",
    "    match_count=0\n",
    "    \n",
    "    # 'The' is commonly found in answers and questions, but doesn't have any meaningfull use in finding the answer\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    if len(split_answer)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        for word in split_answer:\n",
    "            if word in split_question:\n",
    "                match_count += 1\n",
    "    return match_count/len(split_answer)\n",
    "jeopardy['answer_in_question']=jeopardy.apply(answer_match_question,axis=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05637826071470733"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The answer only appears in the question about 6% of the time\n",
    "jeopardy['answer_in_question'].mean()\n",
    "\n",
    "# This means that my friend probably can't just hope that hearing a question will enable him \n",
    "# to figure out the answer. He'll probably have to study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## How often new questions are repeates of older questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9171296488547745"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the data in order of ascending air date\n",
    "jeopardy.sort_values(by='air_date',inplace=True)\n",
    "\n",
    "# Initiate a list and a set\n",
    "question_overlap=[]\n",
    "terms_used=set()\n",
    "\n",
    "# Loop through each row of the data\n",
    "for index,row in jeopardy.iterrows():\n",
    "    split_question=row['clean_question'].split()\n",
    "    # Remove stopwords \n",
    "    split_question=[word for word in split_question if word not in ENGLISH_STOP_WORDS]\n",
    "    match_count=0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question)>0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "jeopardy['question_overlap']=question_overlap\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9171296488547745"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is about 90% overlap between terms in new questions and terms in old questions\n",
    "jeopardy['question_overlap'].mean() \n",
    "# This result doesn't account for phrases, it looks at single terms. But it's worth looking more into the recyling of questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out which terms correspond to high-value questions using a chi-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duc Cao\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Using 800 as the threshold\n",
    "jeopardy['high_value']=0\n",
    "jeopardy.high_value[jeopardy['clean_value'] > 800]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of low value and high value questions the word occurs in\n",
    "def word_count(word):\n",
    "    low_count=0\n",
    "    high_count=0\n",
    "    for index,row in jeopardy.iterrows():\n",
    "        split_question=row['clean_question'].split()\n",
    "        if word in split_question:\n",
    "            if row['high_value']==1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count,low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly pick 10 elements of termed_used\n",
    "comparison_terms=rd.sample(terms_used,10)\n",
    "observed_expected=[]\n",
    "# For each element calculate the observed counts\n",
    "for word in comparison_terms:\n",
    "    observed_expected.append(word_count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of high value and low value questions\n",
    "high_value_count=jeopardy['high_value'].value_counts()[1]\n",
    "low_value_count=jeopardy['high_value'].value_counts()[0]\n",
    "chi_squared=[]\n",
    "\n",
    "# Calculate chi-squared \n",
    "for obs in observed_expected:\n",
    "    total=sum(obs)\n",
    "    total_prop=total/jeopardy.shape[0]\n",
    "    high_count_exp=total_prop*high_value_count\n",
    "    low_count_exp=total_prop*low_value_count\n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([high_count_exp, low_count_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.9267728889671603, pvalue=0.3357028942299553),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.46338644448358013, pvalue=0.49604555208958945),\n",
       " Power_divergenceResult(statistic=2.5317964247338085, pvalue=0.11157312838169751),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.021646150708492677, pvalue=0.8830323245068887),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.7899529284667026, pvalue=0.3741143592744989),\n",
       " Power_divergenceResult(statistic=0.07446818777814278, pvalue=0.7849388502668134)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None of the terms had a significant difference in usage between high value and low value rows\n",
    "chi_squared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (2, 2),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 3),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (2, 4)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The frequencies were all lower than 5, so the chi-squared test isn't as valid. \n",
    "# It would be better to run this test with only terms that have higher frequencies\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
